"""NeuroWeave ä¸»æµç¨‹è„šæœ¬"""

import torch
from torch_geometric.data import Data, DataLoader

from src.contrastive_loss import nt_xent_loss
from text_generation.gpt_module import generate_text
from src.graph_builder import build_graph
from src.graph_embedding_visualizer import visualize_embeddings
from src.graph_to_text import graph_to_text
from src.graph_transformer import GraphEncoder
from src.graph_visualizer import visualize_graph
from src.ner_extraction import extract_entities_and_relations
from src.train_contrastive import train_contrastive_epoch
from config.config import CONFIG


def main():
    """æ‰§è¡Œå®Œæ•´çš„æ–‡æœ¬â†’å›¾â†’æ–‡æœ¬æµç¨‹"""
    print("tgtç³»ç»Ÿå¯åŠ¨!!!")

    # ========== Step 1: ç”¨æˆ·è¾“å…¥ ==========
    user_prompt = "è¯·æå†™ä¸€ä½åœ¨ç°ä»£ç”Ÿæ´»èƒŒæ™¯ä¸‹ï¼Œä¸æ–­åœ¨é›„å¿ƒå£®å¿—ä¸è‡ªæˆ‘æ€€ç–‘ä¹‹é—´æ‘‡æ‘†çš„å¹´è½»ç”·æ€§çš„å¿ƒç†çŠ¶æ€ã€‚ä»–ä»Šå¹´22å²ï¼Œçƒ­çˆ±å¤ªç©ºã€ç§‘æŠ€ä¸å†’é™©ï¼Œä½†æ—¶å¸¸é™·å…¥å¯¹è‡ªæˆ‘ä»·å€¼çš„æ€€ç–‘å’Œæœªæ¥æ–¹å‘çš„è¿·èŒ«ã€‚è¯·æ·±å…¥æŒ–æ˜ä»–çš„å†…å¿ƒç‹¬ç™½ä¸æƒ…æ„Ÿæ³¢åŠ¨ï¼Œç»“åˆç°å®å‹åŠ›ä¸ç†æƒ³ä¹‹é—´çš„çŸ›ç›¾å†²çªï¼Œä½¿æ–‡å­—å…·æœ‰å“²ç†æ€§ä¸ç°å®æ„Ÿã€‚"
    user_profile = {
        "å¹´é¾„": 22,
        "æ€§åˆ«": "ç”·",
        "æ•™è‚²èƒŒæ™¯": "èˆªå¤©å·¥ç¨‹ä¸“ä¸šæœ¬ç§‘ç”Ÿ",
        "èŒä¸š": "å¤ªç©ºç§‘æŠ€åˆåˆ›å…¬å¸çš„å®ä¹ ç”Ÿ",
        "æ€§æ ¼ç‰¹ç‚¹": ["å¥½å¥‡å¿ƒå¼º", "ç†æƒ³ä¸»ä¹‰", "è‡ªæˆ‘åæ€", "å†…å‘", "æƒ…æ„Ÿæ•æ„Ÿ"],
        "å…´è¶£çˆ±å¥½": [
            "å¤ªç©ºæ¢ç´¢",
            "å‰æ²¿ç§‘æŠ€",
            "ç§‘å¹»æ–‡å­¦",
            "æˆ·å¤–å†’é™©ï¼ˆå¦‚å¾’æ­¥ã€æ”€å²©ï¼‰",
            "å“²å­¦ä¸å­˜åœ¨ä¸»ä¹‰é—®é¢˜"
        ],
        "åŠ¨æœºä¸ç›®æ ‡": [
            "å¸Œæœ›ä¸ºäººç±»çš„å¤ªç©ºæœªæ¥åšå‡ºè´¡çŒ®",
            "æ¢¦æƒ³å‚ä¸ç«æ˜Ÿæ¢æµ‹æˆ–å»ºè®¾ä»»åŠ¡",
            "æ¸´æœ›é€šè¿‡ç§‘å­¦ä¸åˆ›æ–°æ‰¾åˆ°è‡ªæˆ‘ä»·å€¼å’Œæ„ä¹‰"
        ],
        "é¢ä¸´çš„æŒ‘æˆ˜": [
            "ç»å¸¸æ€€ç–‘è‡ªå·±çš„èƒ½åŠ›ä¸ä»·å€¼",
            "åœ¨é«˜åº¦ç«äº‰çš„ç¯å¢ƒä¸­æ„Ÿåˆ°å‹åŠ›å·¨å¤§",
            "éš¾ä»¥åœ¨é›„å¿ƒå£®å¿—ä¸æƒ…ç»ªå¥åº·ä¹‹é—´æ‰¾åˆ°å¹³è¡¡",
            "å› å…´è¶£å°ä¼—è€Œæ„Ÿåˆ°å­¤ç‹¬"
        ],
        "å¿ƒç†æ¨¡å¼": {
            "é›„å¿ƒ": "æœ‰å¼ºçƒˆçš„æœªæ¥æ„¿æ™¯ï¼Œè®¾å®šé«˜ç›®æ ‡ï¼Œæ·±å—é©¬æ–¯å…‹å’Œå¡å°”Â·è¨æ ¹ç­‰äººç‰©å½±å“",
            "è‡ªæˆ‘æ€€ç–‘": "å¸¸æœ‰â€œå†’åé¡¶æ›¿è€…â€å¿ƒæ€ï¼Œæ€€ç–‘è‡ªå·±æ˜¯å¦çœŸçš„æœ‰èƒ½åŠ›",
            "åº”å¯¹æ–¹å¼": [
                "å†™æ—¥è®°è®°å½•æ€è€ƒ",
                "é€šè¿‡é˜…è¯»ç§‘å¹»å°è¯´æˆ–ä»°æœ›æ˜Ÿç©ºæ¥é€ƒé¿ç°å®",
                "åœ¨å‹åŠ›å¤§æ—¶æœ‰æ—¶ä¼šæ‹–å»¶"
            ]
        }
    }

    # ========== Step 2: æ–‡æœ¬ç”Ÿæˆ ==========
    print("\nğŸ§  Step 1: æ–‡æœ¬ç”Ÿæˆ")
    long_text = generate_text(user_prompt, user_profile)
    print("ğŸ“„ ç”Ÿæˆæ–‡æœ¬:\n", long_text)

    # ========== Step 3: å®ä½“ä¸å…³ç³»æŠ½å– ==========
    print("\nğŸ” Step 2: å®ä½“è¯†åˆ«ä¸å…³ç³»æŠ½å–")
    graph_data = extract_entities_and_relations(long_text)
    print("ğŸ§© å›¾ç»“æ„æ•°æ®:", graph_data)

    # ========== Step 4: æ„å»ºå›¾ ==========
    print("\nğŸ•¸ Step 3: æ„å»ºå›¾")
    graph = build_graph(graph_data["nodes"], graph_data["edges"])
    print(f"âœ… æˆåŠŸæ„å»ºå›¾ï¼š{graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {graph.number_of_edges()} æ¡è¾¹")
    visualize_graph(graph, output_file="graph_output.html")

    # ========== Step 5: å›¾ç»“æ„ç¼–ç  ==========
    print("\nğŸ”¬ Step 4: å›¾ç»“æ„ç¼–ç ")
    node_id_map = {node_id: idx for idx, node_id in enumerate(graph.nodes)}
    num_nodes = len(node_id_map)
    x = torch.eye(num_nodes)

    edge_index = torch.tensor([
        [node_id_map[src] for src, tgt in graph.edges],
        [node_id_map[tgt] for src, tgt in graph.edges]
    ], dtype=torch.long)

    data = Data(x=x, edge_index=edge_index)

    # æ ¹æ®é…ç½®æ„å»ºå›¾ç¼–ç å™¨
    model = GraphEncoder(
        in_channels=num_nodes,
        hidden_channels=CONFIG["graph_encoder"]["hidden_channels"],
        out_channels=CONFIG["graph_encoder"]["out_channels"],
        heads=CONFIG["graph_encoder"].get("heads", 2),
    )
    embeddings = model(data.x, data.edge_index)
    print("ğŸ§  å¾—åˆ°èŠ‚ç‚¹è¯­ä¹‰åµŒå…¥ï¼Œshape:", embeddings.shape)

    if embeddings.shape[0] >= 2:
        visualize_embeddings(embeddings, labels=[graph.nodes[n]["label"] for n in graph.nodes])
    else:
        print("âš ï¸ å¯è§†åŒ–è·³è¿‡ï¼šèŠ‚ç‚¹æ•°ä¸è¶³")

    # ========== Step 6: å¯¹æ¯”å­¦ä¹  ==========
    print("\nğŸ¯ Step 5: å¯¹æ¯”å­¦ä¹ ")
    mid = embeddings.shape[0] // 2
    if mid > 0:
        z1, z2 = embeddings[:mid], embeddings[mid:mid*2]
        loss = nt_xent_loss(z1, z2)
        print("ğŸ§  å¯¹æ¯”å­¦ä¹  NT-Xent Loss:", loss.item())
    else:
        print("âš ï¸ èŠ‚ç‚¹å¤ªå°‘ï¼Œè·³è¿‡å¯¹æ¯”æŸå¤±")

    # ========== Step 7: å›¾è½¬æ–‡æœ¬æ¢ç´¢ ==========
    print("\nğŸ“ Step 6: å›¾è½¬æ–‡æœ¬æ¢ç´¢")
    try:
        text_prompt = graph_to_text(graph, embeddings, target_node_id="0")
        print("ğŸ“œ ç”Ÿæˆçš„æ–°æ¢ç´¢æç¤ºï¼š", text_prompt)
    except Exception as e:
        print("âš ï¸ å›¾è½¬æ–‡æœ¬å¤±è´¥ï¼š", e)

    # ========== Step 8: å›¾åµŒå…¥è®­ç»ƒ ==========
    print("\nğŸš€ Step 7: å›¾åµŒå…¥å¯¹æ¯”è®­ç»ƒ")
    if num_nodes >= 2:
        loader = DataLoader([data, data], batch_size=2)

        # æ ¹æ®é…ç½®è®¾ç½®å­¦ä¹ ç‡ä¸è®­ç»ƒè½®æ•°
        optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG["training"]["lr"])

        for epoch in range(CONFIG["training"]["epochs"]):
            epoch_loss = train_contrastive_epoch(model, loader, optimizer)
            print(f"Epoch {epoch + 1}: contrastive loss = {epoch_loss:.4f}")
    else:
        print("âš ï¸ èŠ‚ç‚¹è¿‡å°‘ï¼Œè·³è¿‡è®­ç»ƒæµç¨‹")

    print("\nâœ… æ‰€æœ‰æµç¨‹å®Œæˆï¼Œtgt å®Œæˆä¸€æ¬¡å¾ªç¯")

if __name__ == "__main__":
    main()