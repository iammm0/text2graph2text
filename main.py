import torch
from torch_geometric.data import Data, DataLoader

from src.contrastive_loss import nt_xent_loss
from src.gpt_module import generate_text
from src.graph_builder import build_graph
from src.graph_embedding_visualizer import visualize_embeddings
from src.graph_to_text import graph_to_text
from src.graph_transformer import GraphEncoder
from src.graph_visualizer import visualize_graph
from src.ner_extraction import extract_entities_and_relations_gpt
from src.train_contrastive import train_contrastive_epoch


def main():
    print("ğŸ‰ NeuroWeave å¯åŠ¨ï¼šæ–‡æœ¬-å›¾è°±æ™ºèƒ½ç”Ÿæˆç³»ç»Ÿ")

    # ========== Step 1: ç”¨æˆ·è¾“å…¥ ==========
    user_prompt = "Describe the mental patterns of a person who constantly oscillates between ambition and self-doubt in the context of modern life."
    user_profile = {
        "age": 22,
        "gender": "male",
        "interests": ["space", "technology", "adventure"]
    }

    # ========== Step 2: æ–‡æœ¬ç”Ÿæˆ ==========
    print("\nğŸ§  Step 1: æ–‡æœ¬ç”Ÿæˆ")
    long_text = generate_text(user_prompt, user_profile)
    print("ğŸ“„ ç”Ÿæˆæ–‡æœ¬:\n", long_text)

    # ========== Step 3: å®ä½“ä¸å…³ç³»æŠ½å– ==========
    print("\nğŸ” Step 2: å®ä½“è¯†åˆ«ä¸å…³ç³»æŠ½å–")
    graph_data = extract_entities_and_relations_gpt(long_text)
    print("ğŸ§© å›¾ç»“æ„æ•°æ®:", graph_data)

    # ========== Step 4: æ„å»ºå›¾ ==========
    print("\nğŸ•¸ Step 3: æ„å»ºå›¾")
    graph = build_graph(graph_data["nodes"], graph_data["edges"])
    print(f"âœ… æˆåŠŸæ„å»ºå›¾ï¼š{graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {graph.number_of_edges()} æ¡è¾¹")
    visualize_graph(graph, output_file="graph_output.html")

    # ========== Step 5: å›¾ç»“æ„ç¼–ç  ==========
    print("\nğŸ”¬ Step 4: å›¾ç»“æ„ç¼–ç ")
    node_id_map = {node_id: idx for idx, node_id in enumerate(graph.nodes)}
    num_nodes = len(node_id_map)
    x = torch.eye(num_nodes)

    edge_index = torch.tensor([
        [node_id_map[src] for src, tgt in graph.edges],
        [node_id_map[tgt] for src, tgt in graph.edges]
    ], dtype=torch.long)

    data = Data(x=x, edge_index=edge_index)
    model = GraphEncoder(in_channels=num_nodes, hidden_channels=32, out_channels=16)
    embeddings = model(data.x, data.edge_index)
    print("ğŸ§  å¾—åˆ°èŠ‚ç‚¹è¯­ä¹‰åµŒå…¥ï¼Œshape:", embeddings.shape)

    if embeddings.shape[0] >= 2:
        visualize_embeddings(embeddings, labels=[graph.nodes[n]["label"] for n in graph.nodes])
    else:
        print("âš ï¸ å¯è§†åŒ–è·³è¿‡ï¼šèŠ‚ç‚¹æ•°ä¸è¶³")

    # ========== Step 6: å¯¹æ¯”å­¦ä¹  ==========
    print("\nğŸ¯ Step 5: å¯¹æ¯”å­¦ä¹ ")
    mid = embeddings.shape[0] // 2
    if mid > 0:
        z1, z2 = embeddings[:mid], embeddings[mid:mid*2]
        loss = nt_xent_loss(z1, z2)
        print("ğŸ§  å¯¹æ¯”å­¦ä¹  NT-Xent Loss:", loss.item())
    else:
        print("âš ï¸ èŠ‚ç‚¹å¤ªå°‘ï¼Œè·³è¿‡å¯¹æ¯”æŸå¤±")

    # ========== Step 7: å›¾è½¬æ–‡æœ¬æ¢ç´¢ ==========
    print("\nğŸ“ Step 6: å›¾è½¬æ–‡æœ¬æ¢ç´¢")
    try:
        text_prompt = graph_to_text(graph, embeddings, target_node_id="0")
        print("ğŸ“œ ç”Ÿæˆçš„æ–°æ¢ç´¢æç¤ºï¼š", text_prompt)
    except Exception as e:
        print("âš ï¸ å›¾è½¬æ–‡æœ¬å¤±è´¥ï¼š", e)

    # ========== Step 8: å›¾åµŒå…¥è®­ç»ƒ ==========
    print("\nğŸš€ Step 7: å›¾åµŒå…¥å¯¹æ¯”è®­ç»ƒ")
    if num_nodes >= 2:
        loader = DataLoader([data, data], batch_size=2)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.005)

        for epoch in range(10):
            epoch_loss = train_contrastive_epoch(model, loader, optimizer)
            print(f"Epoch {epoch+1}: contrastive loss = {epoch_loss:.4f}")
    else:
        print("âš ï¸ èŠ‚ç‚¹è¿‡å°‘ï¼Œè·³è¿‡è®­ç»ƒæµç¨‹")

    print("\nâœ… æ‰€æœ‰æµç¨‹å®Œæˆï¼ŒNeuroWeave å®Œæˆä¸€æ¬¡å¾ªç¯")

if __name__ == "__main__":
    main()
